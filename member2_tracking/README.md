# Football Vision - Member 2: Player Tracking

This module implements the **Multi-Object Tracking (MOT)** subsystem for the Football Vision project. It receives object detections (bounding boxes) and assigns unique IDs to players across video frames, handling occlusions and re-identification using the **SORT (Simple Online and Realtime Tracking)** algorithm.

## Core Logic & Algorithm
The tracking engine is based on **SORT (Simple Online and Realtime Tracking)**.
* **Implementation:** The core algorithm is located in the `libs/` folder and is sourced from the official repository [abewley/sort](https://github.com/abewley/sort).
* **Integration:** The `run_tracker.py` script wraps this algorithm to process YOLO detections (JSON) and output consistent trajectory data.

## Validation & Performance
To strictly evaluate performance, the system was tested on the **SoccerNet Tracking 2023** dataset (`snmot-060`), chosen for its high-quality **Ground Truth annotations**.

### Parameter Tuning & Optimization
We conducted multiple experiments to find the optimal balance between tracking stability (IDF1) and detection coverage (MOTA/Recall).

| Experiment | Configuration | MOTA | IDF1 | Recall | ID Sw. | Verdict |
| :--- | :--- | :--- | :--- | :--- | :--- | :--- |
| **Test 1** (Baseline) | `max_age=1`, `min_hits=5`, `iou=0.01` | 95.9% | 79.5% | 96.5% | **58** | Good baseline, but `max_age` too low for occlusions. |
| **Test 2** (Strict) | `max_age=50`, `min_hits=3`, `iou=0.3` | 93.8% | 73.1% | 94.4% | 88 | `iou` too strict for fast sprints, causing track fragmentation. |
| **Test 3** (Optimal) | `max_age=25`, `min_hits=3`, `iou=0.05` | **96.8%** | **80.4%** | **97.3%** | 60 | **Best Result.** Balanced buffer and tolerance for fast movements. |

### Final Results Analysis
The **Test 3** configuration was selected for the final pipeline.
* **MOTA (96.8%)**: By lowering the IOU threshold to `0.05`, the system successfully tracks players even during sudden accelerations where bounding box overlap is minimal.
* **IDF1 (80.4%)**: Increasing `max_age` to 25 frames (1 second) allows the tracker to "remember" players during short occlusions, significantly improving ID stability compared to the baseline.

## Video Demo
Here is a demonstration of the optimal configuration (Test 3) on the validation sequence.

https://github.com/user-attachments/assets/8f8e1563-e1f4-4764-9916-2ce7e9fca493


##  Installation

Follow these steps to set up the development environment.

### 1. Create a Virtual Environment
It is better use a virtual environment to isolate dependencies.

**MacOS / Linux:**
```bash
python3 -m venv venv
source venv/bin/activate
```

**Windows:**
```bash
python -m venv venv
.\venv\Scripts\activate
```

### 2. Install Dependencies

Once the environment is active, install the required libraries:

```bash
pip install -r requirements.txt
```

## Pipeline Usage
The project is divided into 4 main steps.

### 1. Data Preparation (convert_csv_to_json.py)

The tracker works with JSON files. If your data is in the standard MOTChallenge format (det.txt), you must convert it first.

```bash
python src/convert_csv_to_json.py --input data/path/to/det.txt --output data/input_data.json
```

**Available Flags:**
- `--input`: Path to the original detection file (.txt).
- `--output`: (Optional) Path to the destination JSON file.

### 2. Run Tracker (run_tracker.py)

This is the main script that processes frames and assigns IDs to players.

**SORT Example:**

```bash
python src/run_tracker.py --input data/input_data.json --algo sort
```

**ByteTrack Example:**

```bash
python src/run_tracker.py --input data/input_data.json --algo bytetrack --conf 0.3 --output_name results_bt.json
```

**Available Flags:**
- `--input`: JSON file containing detections (Required).
- `--algo`: Algorithm to use: `sort` or `bytetrack` (Default: `sort`).
- `--output_name`: Name of the output file saved in `data/outputs/` (Optional).
- `--conf`: (ByteTrack Only) Minimum confidence to start a new track (e.g., 0.3 for dark videos, default 0.6).
- `--iou`: Intersection Over Union threshold.
  - For SORT: Low value (e.g., 0.05) = Aggressive matching.
  - For ByteTrack: High value (e.g., 0.95) = Aggressive matching.
- `--age`: Tracker memory (number of frames to keep a lost ID alive).

### 3. Video Visualization (visualize_tracking.py)

Generates a video with bounding boxes and IDs overlaid to visually verify the results.

```bash
python src/visualize_tracking.py --video data/original_video.mp4 --json data/outputs/results_bt.json
```

**Available Flags:**
- `--video`: Path to the original video (.mp4) or image folder.
- `--json`: Path to the JSON file generated by the tracker.
- `--output`: (Optional) Path/Name of the final output video.

### 4. Metric Evaluation (Benchmark)

To calculate standard metrics like MOTA and IDF1, you need to compare the output with the Ground Truth (GT).

**Step A: Convert JSON Output to TXT**

```bash
python src/convert_json_to_result.py --input data/outputs/results_bt.json
```

This creates a `.txt` file in the same directory as the JSON.

**Step B: Calculate Metrics**

```bash
python src/evaluate_metric.py --gt data/path/to/gt.txt --pred data/outputs/results_bt.txt
```

**Available Flags:**
- `--gt`: Official Ground Truth file (.txt).
- `--pred`: Converted prediction file (.txt).
- `--iou`: IOU Threshold to consider a prediction correct (Default 0.5).

